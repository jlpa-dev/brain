{
    "componentChunkName": "component---src-templates-cheatsheet-js",
    "path": "/cheatsheets/kubernetes/",
    "result": {"data":{"site":{"siteMetadata":{"title":"JLPA | BLOG"}},"markdownRemark":{"id":"dcc7e9fe-c43d-5d2e-90e4-a2b75fddf2f6","excerpt":"kubernetes shortcuts & cheatsheet 1. Learning Docker Basics 2. Logging Use a DaemonSet for Pods that need to run one per machine, because they provide a machineâ€¦","html":"<h1>kubernetes shortcuts &#x26; cheatsheet</h1>\n<h2>1. <a href=\"#learning-k8s-basics\">Learning Docker Basics</a></h2>\n<h2>2. <a href=\"#logging\">Logging</a></h2>\n<p>Use a DaemonSet for Pods that need to run one per machine, because they provide a machine-specific system service.</p>\n<p>Learning k8s basics</p>\n<p>For example, to mark a node\nunschedulable, run this command:</p>\n<pre><code class=\"language-shell\">kubectl cordon $NODENAME\n</code></pre>\n<p>Delte the pod when it went to unknown status if node is down</p>\n<pre><code>kubectl delete pod &#x3C;pod_name> --grace-period=0 --force\n</code></pre>\n<p>after running counter pod with two container for logging get the log from each container</p>\n<pre><code>kubectl logs counter count-log-1\nkubectl logs counter count-log-2\n</code></pre>\n<p>managing kubernetes using imperative commands:</p>\n<pre><code>kubectl run nginx --image nginx\nkubectl create deployment nginx --image nginx\n</code></pre>\n<p>imperative object configuration:</p>\n<pre><code>kubectl create -f nginx.yaml\t                        \nkubectl delete -f nginx.yaml -f redis.yam\t\nkubectl replace -f nginx.yaml\n</code></pre>\n<p>Imperative object configuration:</p>\n<p>How to create objects:</p>\n<pre><code>kubectl create -f &#x3C;filename|url>\n</code></pre>\n<p>How to update objects:</p>\n<pre><code>kubectl replace -f &#x3C;filename|url>\n</code></pre>\n<p>How to view an object:</p>\n<pre><code>kubectl delete -f &#x3C;filename|url>\n</code></pre>\n<p>How to view an object:</p>\n<pre><code>kubectl get -f &#x3C;filename|url> -o yaml\n</code></pre>\n<p>Creating and editing an object from a URL without saving the configuration:</p>\n<pre><code>kubectl create -f &#x3C;url> --edit\n</code></pre>\n<p>declarative object configuration:</p>\n<p>How to create objects:</p>\n<pre><code>kubectl apply -f &#x3C;directory>/\nkubectl apply -f https://k8s.io/examples/application/simple_deployment.yaml\nkubectl get -f https://k8s.io/examples/application/simple_deployment.yaml -o yaml\n</code></pre>\n<p>How to update objects:</p>\n<pre><code>kubectl apply -f &#x3C;directory>/\n</code></pre>\n<p>How to delete objects:</p>\n<pre><code>kubectl delete -f &#x3C;filename>\nkubectl apply -f &#x3C;directory/> --prune -l &#x3C;labels>\n</code></pre>\n<p>How to view an object:</p>\n<pre><code>kubectl get -f &#x3C;filename|url> -o yaml\n</code></pre>\n<p>Get the details of the kube cluster</p>\n<pre><code>kubectl config current-context \nkubectl cluster-info\n</code></pre>\n<h1>kubernetes objects</h1>\n<p>managing kubernetes using imperative commands:</p>\n<pre><code>kubectl run nginx --image nginx\nkubectl create deployment nginx --image nginx\n</code></pre>\n<p>imperative object configuration:</p>\n<pre><code>kubectl create -f nginx.yaml\t                        \nkubectl delete -f nginx.yaml -f redis.yam\t\nkubectl replace -f nginx.yaml\n</code></pre>\n<p>Imperative object configuration:</p>\n<p>How to create objects:</p>\n<pre><code>kubectl create -f &#x3C;filename|url>\n</code></pre>\n<p>How to update objects:</p>\n<pre><code>kubectl replace -f &#x3C;filename|url>\n</code></pre>\n<p>How to view an object:</p>\n<pre><code>kubectl delete -f &#x3C;filename|url>\n</code></pre>\n<p>How to view an object:</p>\n<pre><code>kubectl get -f &#x3C;filename|url> -o yaml\n</code></pre>\n<p>Creating and editing an object from a URL without saving the configuration:</p>\n<pre><code>kubectl create -f &#x3C;url> --edit\n</code></pre>\n<p>declarative object configuration:</p>\n<p>How to create objects:</p>\n<pre><code>kubectl apply -f &#x3C;directory>/\nkubectl apply -f https://k8s.io/examples/application/simple_deployment.yaml\nkubectl get -f https://k8s.io/examples/application/simple_deployment.yaml -o yaml\n</code></pre>\n<p>How to update objects:</p>\n<pre><code>kubectl apply -f &#x3C;directory>/\n</code></pre>\n<p>How to delete objects:</p>\n<pre><code>kubectl delete -f &#x3C;filename>\nkubectl apply -f &#x3C;directory/> --prune -l &#x3C;labels>\n</code></pre>\n<p>How to view an object:</p>\n<pre><code>kubectl get -f &#x3C;filename|url> -o yaml\n</code></pre>\n<p>Migrating from imperative commands to imperative object configuration:</p>\n<pre><code>Export the live object to a local object configuration file:\n\nkubectl get &#x3C;kind>/&#x3C;name> -o yaml --export > &#x3C;kind>_&#x3C;name>.yaml\nManually remove the status field from the object configuration file.\n\nFor subsequent object management, use replace exclusively.\n\nkubectl replace -f &#x3C;kind>_&#x3C;name>.yaml\n</code></pre>\n<p>Migrating from imperative command management to declarative object configuration:</p>\n<pre><code>Migrating from imperative command management to declarative object configuration involves several manual steps:\n\nExport the live object to a local configuration file:\n\nkubectl get &#x3C;kind>/&#x3C;name> -o yaml --export > &#x3C;kind>_&#x3C;name>.yaml\nManually remove the status field from the configuration file.\n\nNote: This step is optional, as kubectl apply does not update the status field even if it is present in the configuration file.\nSet the kubectl.kubernetes.io/last-applied-configuration annotation on the object:\n\nkubectl replace --save-config -f &#x3C;kind>_&#x3C;name>.yaml\nChange processes to use kubectl apply for managing the object exclusively.\n</code></pre>\n<p>Migrating from imperative object configuration to declarative object configuration</p>\n<pre><code>Set the kubectl.kubernetes.io/last-applied-configuration annotation on the object:\n\nkubectl replace --save-config -f &#x3C;kind>_&#x3C;name>.yaml\nChange processes to use kubectl apply for managing the object exclusively.\n</code></pre>\n<p>Defining controller selectors and PodTemplate labels:</p>\n<pre><code>Warning: Updating selectors on controllers is strongly discouraged.\nThe recommended approach is to define a single, immutable PodTemplate label used only by the controller selector with no other semantic meaning.\n\nExample label:\n\nselector:\n    matchLabels:\n        controller-selector: \"extensions/v1beta1/deployment/nginx\"\ntemplate:\n    metadata:\n      labels:\n        controller-selector: \"extensions/v1beta1/deployment/nginx\"\n        \n</code></pre>\n<p>Events</p>\n<pre><code>kubectl get event --field-selector involvedObject.kind=Pod\nkubectl get event --field-selector involvedObject.kind=CronJob\nkubectl get event --field-selector involvedObject.kind=Pod --sort-by=.metadata.creationTimestamp\n\nkubectl get event --field-selector involvedObject.name=hello --sort-by=.metadata.creationTimestamp\nkubectl get events --sort-by=.metadata.creationTimestamp\nkubectl get events --sort-by=.lastTimestamp\nkubectl get events -o=custom-columns=NAME:.metadata.name,NAME:.metadata.creationTimestamp,NAME:.lastTimestamp\n\nkubectl get event --field-selector involvedObject.kind=Pod | grep error\n        \n</code></pre>\n<h2>Logging</h2>\n<pre><code>https://kubernetes.io/docs/concepts/cluster-administration/logging/\n\nkubectl logs pod-name\nkubectl logs job/jon-name\nor\nkubectl logs pod-name -c container-name # if pod has multiple container\nkubectl logs pod-name -c container-name --previous # for the container which has crashed\nor\nkubectl logs pod-name -p -c container-name\n\nkubectl logs --tail=20 pod-name\nkubectl logs --since=1h pod-name\n</code></pre>\n<h2>Organizing resource configurations</h2>\n<p>Many applications require multiple resources to be created, such as a Deployment and a Service. Management of multiple resources can be simplified by grouping them together in the same file (separated by <code>---</code> in YAML). For example:</p>\n<p>{{&#x3C; codenew file=\"application/nginx-app.yaml\" >}}</p>\n<p>Multiple resources can be created the same way as a single resource:</p>\n<pre><code class=\"language-shell\">$ kubectl create -f https://k8s.io/examples/application/nginx-app.yaml\nservice/my-nginx-svc created\ndeployment.apps/my-nginx created\n</code></pre>\n<p>The resources will be created in the order they appear in the file. Therefore, it's best to specify the service first, since that will ensure the scheduler can spread the pods associated with the service as they are created by the controller(s), such as Deployment.</p>\n<p><code>kubectl create</code> also accepts multiple <code>-f</code> arguments:</p>\n<pre><code class=\"language-shell\">$ kubectl create -f https://k8s.io/examples/application/nginx/nginx-svc.yaml -f https://k8s.io/examples/application/nginx/nginx-deployment.yaml\n</code></pre>\n<p>And a directory can be specified rather than or in addition to individual files:</p>\n<pre><code class=\"language-shell\">$ kubectl create -f https://k8s.io/examples/application/nginx/\n</code></pre>\n<p><code>kubectl</code> will read any files with suffixes <code>.yaml</code>, <code>.yml</code>, or <code>.json</code>.</p>\n<p>It is a recommended practice to put resources related to the same microservice or application tier into the same file, and to group all of the files associated with your application in the same directory. If the tiers of your application bind to each other using DNS, then you can then simply deploy all of the components of your stack en masse.</p>\n<p>A URL can also be specified as a configuration source, which is handy for deploying directly from configuration files checked into github:</p>\n<pre><code class=\"language-shell\">$ kubectl create -f https://raw.githubusercontent.com/kubernetes/website/master/content/en/examples/application/nginx/nginx-deployment.yaml\ndeployment.apps/my-nginx created\n</code></pre>\n<h2>Bulk operations in kubectl</h2>\n<p>Resource creation isn't the only operation that <code>kubectl</code> can perform in bulk. It can also extract resource names from configuration files in order to perform other operations, in particular to delete the same resources you created:</p>\n<pre><code class=\"language-shell\">$ kubectl delete -f https://k8s.io/examples/application/nginx-app.yaml\ndeployment \"my-nginx\" deleted\nservice \"my-nginx-svc\" deleted\n</code></pre>\n<p>In the case of just two resources, it's also easy to specify both on the command line using the resource/name syntax:</p>\n<pre><code class=\"language-shell\">$ kubectl delete deployments/my-nginx services/my-nginx-svc\n</code></pre>\n<p>For larger numbers of resources, you'll find it easier to specify the selector (label query) specified using <code>-l</code> or <code>--selector</code>, to filter resources by their labels:</p>\n<pre><code class=\"language-shell\">$ kubectl delete deployment,services -l app=nginx\ndeployment.apps \"my-nginx\" deleted\nservice \"my-nginx-svc\" deleted\n</code></pre>\n<p>Because <code>kubectl</code> outputs resource names in the same syntax it accepts, it's easy to chain operations using <code>$()</code> or <code>xargs</code>:</p>\n<pre><code class=\"language-shell\">$ kubectl get $(kubectl create -f docs/concepts/cluster-administration/nginx/ -o name | grep service)\nNAME           TYPE           CLUSTER-IP   EXTERNAL-IP   PORT(S)      AGE\nmy-nginx-svc   LoadBalancer   10.0.0.208   &#x3C;pending>     80/TCP       0s\n</code></pre>\n<p>With the above commands, we first create resources under <code>examples/application/nginx/</code> and print the resources created with <code>-o name</code> output format\n(print each resource as resource/name). Then we <code>grep</code> only the \"service\", and then print it with <code>kubectl get</code>.</p>\n<p>If you happen to organize your resources across several subdirectories within a particular directory, you can recursively perform the operations on the subdirectories also, by specifying <code>--recursive</code> or <code>-R</code> alongside the <code>--filename,-f</code> flag.</p>\n<p>For instance, assume there is a directory <code>project/k8s/development</code> that holds all of the manifests needed for the development environment, organized by resource type:</p>\n<pre><code>project/k8s/development\nâ”œâ”€â”€ configmap\nâ”‚   â””â”€â”€ my-configmap.yaml\nâ”œâ”€â”€ deployment\nâ”‚   â””â”€â”€ my-deployment.yaml\nâ””â”€â”€ pvc\n    â””â”€â”€ my-pvc.yaml\n</code></pre>\n<p>By default, performing a bulk operation on <code>project/k8s/development</code> will stop at the first level of the directory, not processing any subdirectories. If we had tried to create the resources in this directory using the following command, we would have encountered an error:</p>\n<pre><code class=\"language-shell\">$ kubectl create -f project/k8s/development\nerror: you must provide one or more resources by argument or filename (.json|.yaml|.yml|stdin)\n</code></pre>\n<p>Instead, specify the <code>--recursive</code> or <code>-R</code> flag with the <code>--filename,-f</code> flag as such:</p>\n<pre><code class=\"language-shell\">$ kubectl create -f project/k8s/development --recursive\nconfigmap \"my-config\" created\ndeployment \"my-deployment\" created\npersistentvolumeclaim \"my-pvc\" created\n</code></pre>\n<p>The <code>--recursive</code> flag works with any operation that accepts the <code>--filename,-f</code> flag such as: <code>kubectl {create,get,delete,describe,rollout} etc.</code></p>\n<p>The <code>--recursive</code> flag also works when multiple <code>-f</code> arguments are provided:</p>\n<pre><code class=\"language-shell\">$ kubectl create -f project/k8s/namespaces -f project/k8s/development --recursive\nnamespace \"development\" created\nnamespace \"staging\" created\nconfigmap \"my-config\" created\ndeployment \"my-deployment\" created\npersistentvolumeclaim \"my-pvc\" created\n</code></pre>\n<p>If you're interested in learning more about <code>kubectl</code>, go ahead and read <a href=\"/brain/docs/reference/kubectl/overview/\">kubectl Overview</a>.</p>\n<h2>Using labels effectively</h2>\n<p>The examples we've used so far apply at most a single label to any resource. There are many scenarios where multiple labels should be used to distinguish sets from one another.</p>\n<p>For instance, different applications would use different values for the <code>app</code> label, but a multi-tier application, such as the [guestbook example](<a href=\"https://github.com/kubernetes/examples/tree/%7B%7B\">https://github.com/kubernetes/examples/tree/{{</a>&#x3C; param \"githubbranch\" >}}/guestbook/), would additionally need to distinguish each tier. The frontend could carry the following labels:</p>\n<pre><code class=\"language-yaml\">     labels:\n        app: guestbook\n        tier: frontend\n</code></pre>\n<p>while the Redis master and slave would have different <code>tier</code> labels, and perhaps even an additional <code>role</code> label:</p>\n<pre><code class=\"language-yaml\">     labels:\n        app: guestbook\n        tier: backend\n        role: master\n</code></pre>\n<p>and</p>\n<pre><code class=\"language-yaml\">     labels:\n        app: guestbook\n        tier: backend\n        role: slave\n</code></pre>\n<p>The labels allow us to slice and dice our resources along any dimension specified by a label:</p>\n<pre><code class=\"language-shell\">$ kubectl create -f examples/guestbook/all-in-one/guestbook-all-in-one.yaml\n$ kubectl get pods -Lapp -Ltier -Lrole\nNAME                           READY     STATUS    RESTARTS   AGE       APP         TIER       ROLE\nguestbook-fe-4nlpb             1/1       Running   0          1m        guestbook   frontend   &#x3C;none>\nguestbook-fe-ght6d             1/1       Running   0          1m        guestbook   frontend   &#x3C;none>\nguestbook-fe-jpy62             1/1       Running   0          1m        guestbook   frontend   &#x3C;none>\nguestbook-redis-master-5pg3b   1/1       Running   0          1m        guestbook   backend    master\nguestbook-redis-slave-2q2yf    1/1       Running   0          1m        guestbook   backend    slave\nguestbook-redis-slave-qgazl    1/1       Running   0          1m        guestbook   backend    slave\nmy-nginx-divi2                 1/1       Running   0          29m       nginx       &#x3C;none>     &#x3C;none>\nmy-nginx-o0ef1                 1/1       Running   0          29m       nginx       &#x3C;none>     &#x3C;none>\n$ kubectl get pods -lapp=guestbook,role=slave\nNAME                          READY     STATUS    RESTARTS   AGE\nguestbook-redis-slave-2q2yf   1/1       Running   0          3m\nguestbook-redis-slave-qgazl   1/1       Running   0          3m\n</code></pre>\n<h2>Canary deployments</h2>\n<p>Another scenario where multiple labels are needed is to distinguish deployments of different releases or configurations of the same component. It is common practice to deploy a <em>canary</em> of a new application release (specified via image tag in the pod template) side by side with the previous release so that the new release can receive live production traffic before fully rolling it out.</p>\n<p>For instance, you can use a <code>track</code> label to differentiate different releases.</p>\n<p>The primary, stable release would have a <code>track</code> label with value as <code>stable</code>:</p>\n<pre><code class=\"language-yaml\">     name: frontend\n     replicas: 3\n     ...\n     labels:\n        app: guestbook\n        tier: frontend\n        track: stable\n     ...\n     image: gb-frontend:v3\n</code></pre>\n<p>and then you can create a new release of the guestbook frontend that carries the <code>track</code> label with different value (i.e. <code>canary</code>), so that two sets of pods would not overlap:</p>\n<pre><code class=\"language-yaml\">     name: frontend-canary\n     replicas: 1\n     ...\n     labels:\n        app: guestbook\n        tier: frontend\n        track: canary\n     ...\n     image: gb-frontend:v4\n</code></pre>\n<p>The frontend service would span both sets of replicas by selecting the common subset of their labels (i.e. omitting the <code>track</code> label), so that the traffic will be redirected to both applications:</p>\n<pre><code class=\"language-yaml\">  selector:\n     app: guestbook\n     tier: frontend\n</code></pre>\n<p>You can tweak the number of replicas of the stable and canary releases to determine the ratio of each release that will receive live production traffic (in this case, 3:1).\nOnce you're confident, you can update the stable track to the new application release and remove the canary one.</p>\n<p>For a more concrete example, check the <a href=\"https://github.com/kelseyhightower/talks/tree/master/kubecon-eu-2016/demo#deploy-a-canary\">tutorial of deploying Ghost</a>.</p>\n<h2>Updating labels</h2>\n<p>Sometimes existing pods and other resources need to be relabeled before creating new resources. This can be done with <code>kubectl label</code>.\nFor example, if you want to label all your nginx pods as frontend tier, simply run:</p>\n<pre><code class=\"language-shell\">$ kubectl label pods -l app=nginx tier=fe\npod/my-nginx-2035384211-j5fhi labeled\npod/my-nginx-2035384211-u2c7e labeled\npod/my-nginx-2035384211-u3t6x labeled\n</code></pre>\n<p>This first filters all pods with the label \"app=nginx\", and then labels them with the \"tier=fe\".\nTo see the pods you just labeled, run:</p>\n<pre><code class=\"language-shell\">$ kubectl get pods -l app=nginx -L tier\nNAME                        READY     STATUS    RESTARTS   AGE       TIER\nmy-nginx-2035384211-j5fhi   1/1       Running   0          23m       fe\nmy-nginx-2035384211-u2c7e   1/1       Running   0          23m       fe\nmy-nginx-2035384211-u3t6x   1/1       Running   0          23m       fe\n</code></pre>\n<p>This outputs all \"app=nginx\" pods, with an additional label column of pods' tier (specified with <code>-L</code> or <code>--label-columns</code>).</p>\n<p>For more information, please see <a href=\"/brain/docs/concepts/overview/working-with-objects/labels/\">labels</a> and <a href=\"/brain/docs/reference/generated/kubectl/kubectl-commands/#label\">kubectl label</a>.</p>\n<h2>Updating annotations</h2>\n<p>Sometimes you would want to attach annotations to resources. Annotations are arbitrary non-identifying metadata for retrieval by API clients such as tools, libraries, etc. This can be done with <code>kubectl annotate</code>. For example:</p>\n<pre><code class=\"language-shell\">$ kubectl annotate pods my-nginx-v4-9gw19 description='my frontend running nginx'\n$ kubectl get pods my-nginx-v4-9gw19 -o yaml\napiversion: v1\nkind: pod\nmetadata:\n  annotations:\n    description: my frontend running nginx\n...\n</code></pre>\n<p>For more information, please see <a href=\"/brain/docs/concepts/overview/working-with-objects/annotations/\">annotations</a> and <a href=\"/brain/docs/reference/generated/kubectl/kubectl-commands/#annotate\">kubectl annotate</a> document.</p>\n<h2>Scaling your application</h2>\n<p>When load on your application grows or shrinks, it's easy to scale with <code>kubectl</code>. For instance, to decrease the number of nginx replicas from 3 to 1, do:</p>\n<pre><code class=\"language-shell\">$ kubectl scale deployment/my-nginx --replicas=1\ndeployment.extensions/my-nginx scaled\n</code></pre>\n<p>Now you only have one pod managed by the deployment.</p>\n<pre><code class=\"language-shell\">$ kubectl get pods -l app=nginx\nNAME                        READY     STATUS    RESTARTS   AGE\nmy-nginx-2035384211-j5fhi   1/1       Running   0          30m\n</code></pre>\n<p>To have the system automatically choose the number of nginx replicas as needed, ranging from 1 to 3, do:</p>\n<pre><code class=\"language-shell\">$ kubectl autoscale deployment/my-nginx --min=1 --max=3\nhorizontalpodautoscaler.autoscaling/my-nginx autoscaled\n</code></pre>\n<p>Now your nginx replicas will be scaled up and down as needed, automatically.</p>\n<p>For more information, please see <a href=\"/brain/docs/reference/generated/kubectl/kubectl-commands/#scale\">kubectl scale</a>, <a href=\"/brain/docs/reference/generated/kubectl/kubectl-commands/#autoscale\">kubectl autoscale</a> and <a href=\"/brain/docs/tasks/run-application/horizontal-pod-autoscale/\">horizontal pod autoscaler</a> document.</p>\n<h2>In-place updates of resources</h2>\n<p>Sometimes it's necessary to make narrow, non-disruptive updates to resources you've created.</p>\n<h3>kubectl apply</h3>\n<p>It is suggested to maintain a set of configuration files in source control (see <a href=\"http://martinfowler.com/bliki/InfrastructureAsCode.html\">configuration as code</a>),\nso that they can be maintained and versioned along with the code for the resources they configure.\nThen, you can use <a href=\"/brain/docs/reference/generated/kubectl/kubectl-commands/#apply\"><code>kubectl apply</code></a> to push your configuration changes to the cluster.</p>\n<p>This command will compare the version of the configuration that you're pushing with the previous version and apply the changes you've made, without overwriting any automated changes to properties you haven't specified.</p>\n<pre><code class=\"language-shell\">$ kubectl apply -f https://k8s.io/examples/application/nginx/nginx-deployment.yaml\ndeployment.apps/my-nginx configured\n</code></pre>\n<p>Note that <code>kubectl apply</code> attaches an annotation to the resource in order to determine the changes to the configuration since the previous invocation. When it's invoked, <code>kubectl apply</code> does a three-way diff between the previous configuration, the provided input and the current configuration of the resource, in order to determine how to modify the resource.</p>\n<p>Currently, resources are created without this annotation, so the first invocation of <code>kubectl apply</code> will fall back to a two-way diff between the provided input and the current configuration of the resource. During this first invocation, it cannot detect the deletion of properties set when the resource was created. For this reason, it will not remove them.</p>\n<p>All subsequent calls to <code>kubectl apply</code>, and other commands that modify the configuration, such as <code>kubectl replace</code> and <code>kubectl edit</code>, will update the annotation, allowing subsequent calls to <code>kubectl apply</code> to detect and perform deletions using a three-way diff.</p>\n<p>{{&#x3C; note >}}\n<strong>Note:</strong> To use apply, always create resource initially with either <code>kubectl apply</code> or <code>kubectl create --save-config</code>.\n{{&#x3C; /note >}}</p>\n<h3>kubectl edit</h3>\n<p>Alternatively, you may also update resources with <code>kubectl edit</code>:</p>\n<pre><code class=\"language-shell\">$ kubectl edit deployment/my-nginx\n</code></pre>\n<p>This is equivalent to first <code>get</code> the resource, edit it in text editor, and then <code>apply</code> the resource with the updated version:</p>\n<pre><code class=\"language-shell\">$ kubectl get deployment my-nginx -o yaml > /tmp/nginx.yaml\n$ vi /tmp/nginx.yaml\n# do some edit, and then save the file\n$ kubectl apply -f /tmp/nginx.yaml\ndeployment.apps/my-nginx configured\n$ rm /tmp/nginx.yaml\n</code></pre>\n<p>This allows you to do more significant changes more easily. Note that you can specify the editor with your <code>EDITOR</code> or <code>KUBE_EDITOR</code> environment variables.</p>\n<p>For more information, please see <a href=\"/brain/docs/reference/generated/kubectl/kubectl-commands/#edit\">kubectl edit</a> document.</p>\n<h3>kubectl patch</h3>\n<p>You can use <code>kubectl patch</code> to update API objects in place. This command supports JSON patch,\nJSON merge patch, and strategic merge patch. See\n<a href=\"/brain/docs/tasks/run-application/update-api-object-kubectl-patch/\">Update API Objects in Place Using kubectl patch</a>\nand\n<a href=\"/brain/docs/reference/generated/kubectl/kubectl-commands/#patch\">kubectl patch</a>.</p>\n<h2>Disruptive updates</h2>\n<p>In some cases, you may need to update resource fields that cannot be updated once initialized, or you may just want to make a recursive change immediately, such as to fix broken pods created by a Deployment. To change such fields, use <code>replace --force</code>, which deletes and re-creates the resource. In this case, you can simply modify your original configuration file:</p>\n<pre><code class=\"language-shell\">$ kubectl replace -f https://k8s.io/examples/application/nginx/nginx-deployment.yaml --force\ndeployment.apps/my-nginx deleted\ndeployment.apps/my-nginx replaced\n</code></pre>\n<h2>Updating your application without a service outage</h2>\n<p>At some point, you'll eventually need to update your deployed application, typically by specifying a new image or image tag, as in the canary deployment scenario above. <code>kubectl</code> supports several update operations, each of which is applicable to different scenarios.</p>\n<p>We'll guide you through how to create and update applications with Deployments. If your deployed application is managed by Replication Controllers,\nyou should read <a href=\"/brain/docs/tasks/run-application/rolling-update-replication-controller/\">how to use <code>kubectl rolling-update</code></a> instead.</p>\n<p>Let's say you were running version 1.7.9 of nginx:</p>\n<pre><code class=\"language-shell\">$ kubectl run my-nginx --image=nginx:1.7.9 --replicas=3\ndeployment.apps/my-nginx created\n</code></pre>\n<p>To update to version 1.9.1, simply change <code>.spec.template.spec.containers[0].image</code> from <code>nginx:1.7.9</code> to <code>nginx:1.9.1</code>, with the kubectl commands we learned above.</p>\n<pre><code class=\"language-shell\">$ kubectl edit deployment/my-nginx\n</code></pre>\n<p>That's it! The Deployment will declaratively update the deployed nginx application progressively behind the scene. It ensures that only a certain number of old replicas may be down while they are being updated, and only a certain number of new replicas may be created above the desired number of pods. To learn more details about it, visit <a href=\"/brain/docs/concepts/workloads/controllers/deployment/\">Deployment page</a>.</p>\n<p>{{% /capture %}}</p>\n<p>{{% capture whatsnext %}}</p>\n<ul>\n<li><a href=\"/brain/docs/tasks/debug-application-cluster/debug-application-introspection/\">Learn about how to use <code>kubectl</code> for application introspection and debugging.</a></li>\n<li><a href=\"/brain/docs/concepts/configuration/overview/\">Configuration Best Practices and Tips</a></li>\n</ul>\n<p>{{% /capture %}}</p>","frontmatter":{"title":"Kubernetes","date":null,"frontimage":null,"description":null},"fields":{"slug":"/kubernetes/"}},"previous":{"fields":{"slug":"/grid/"},"frontmatter":{"title":"CSS Grid"}},"next":{"fields":{"slug":"/postgresql/"},"frontmatter":{"title":"PostgreSQL"}}},"pageContext":{"id":"dcc7e9fe-c43d-5d2e-90e4-a2b75fddf2f6","previousPostId":"9f238983-6266-597c-86a8-b23cc2fbc781","nextPostId":"430518ca-949f-591b-9585-96f8dd296d61"}},
    "staticQueryHashes": ["2841359383","3865664119"]}